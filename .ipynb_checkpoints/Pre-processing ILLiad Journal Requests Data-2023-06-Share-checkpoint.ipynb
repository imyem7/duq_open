{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "befce616",
   "metadata": {},
   "source": [
    "### Automating Journal Title Retrieval using Python: A Guide for ISSN and ISBN Lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c110b9",
   "metadata": {},
   "source": [
    "### 1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d931e",
   "metadata": {},
   "source": [
    "### 2. Auto Look Up \n",
    "\n",
    "- The following code reads in an EXCEL file and selects specific columns to work with. It then filters the resulting DataFrame to only include `Article` requests and prints out some summary information about the DataFrame.\n",
    "- For each transaction number and corresponding ISSN in our lists, we first clean the ISSN string to remove any hyphens or spaces. Then, we check the length of the cleaned string to determine whether it's an 8-digit or 13- or 10-digit ISSN.\n",
    "- If the cleaned string is 8 digits, we add a hyphen in the appropriate place to make it a valid ISSN. Then, we use the Crossref module to check whether the journal with that ISSN exists. If it does, we extract the first ISSN in the list of ISSNs (sometimes journals have multiple ISSNs), and we use this ISSN to look up the title of the journal in the Crossref database.\n",
    "- If the cleaned string is 13 or 10 digits, we assume it's an ISBN (International Standard Book Number) and we use the Googlebooks module to look up the title of the book. We extract the first identifier in the list of industry identifiers (sometimes books have multiple ISBNs), and we use this identifier as the ISSN for our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d46d0f2-9ba1-4d0a-bd15-9075f76d92e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your multipass ID:  muny\n",
      "Enter ILLiad Monthly File Name: `Do not enter .xlsx part` illiad-export-april-2020\n"
     ]
    }
   ],
   "source": [
    "multipass_id = input(\"Enter your multipass ID: \")\n",
    "input_name = input(\"Enter ILLiad Monthly File Name: `Do not enter .xlsx part`\" )\n",
    "input_file_name = input_name+\".xlsx\"\n",
    "\n",
    "input_file_path = (f\"C:\\\\Users\\\\{multipass_id}\\\\Box\\\\\\Annual Report Procedures\\\\ILLiad Statistics\\\\ill_titles_data\\\\{input_file_name}\")\n",
    "\n",
    "# Select columns we need\n",
    "ill_df = pd.read_excel(input_file_path, usecols=[\"Transaction Number\", \"Request Type\",\"Process Type\", \"Photo Journal Title\",\n",
    "                                                 \"Photo Journal Year\", \"ISSN\", \"Creation Date\",\"Status\", \"Transaction Status\", \n",
    "                                                 \"Reason For Cancellation\",\"Document Type\", \"Department\"])\n",
    "# Filter for only Article requests\n",
    "filter = ill_df[\"Request Type\"].isin([\"Article\"])\n",
    "article = ill_df[filter]\n",
    "\n",
    "\"\"\" ISSN LOOK UP\"\"\"\n",
    "issn_list = list(article[\"ISSN\"])\n",
    "transaction_list = list(article['Transaction Number'])\n",
    "\n",
    "# Initialize a new dataframe\n",
    "new_df = pd.DataFrame(columns=['Transaction Number', 'issn', 'title', 'original'])\n",
    "\n",
    "# Update the Transaction Number\n",
    "for idx, v in enumerate(transaction_list):\n",
    "    new_df.loc[idx, 'Transaction Number'] = v\n",
    "\n",
    "# # Iterate through the transaction list and search for corresponding ISSNs and titles from CrossRef\n",
    "for idx, x in enumerate(issn_list):\n",
    "    x = str(x)\n",
    "    new_df.loc[idx, 'original'] = x\n",
    "    x_short = x.replace(\"-\", \"\").replace(\" \", \"\").strip()\n",
    "\n",
    "    if len(x_short) == 8:\n",
    "        x_issn = x_short[0:4] + \"-\" + x_short[4:8]\n",
    "        \n",
    "        api_url = f\"https://api.crossref.org/journals/{x_issn}\"\n",
    "        \n",
    "        try:\n",
    "            headers = {'User-Agent': 'ISSN-info/1.0 (mailto:myexample@email.com)'}\n",
    "            response = requests.get(api_url, headers=headers)\n",
    "            data = response.json()\n",
    "            \n",
    "            # Retrieve the ISSN and title from the response\n",
    "            if \"message\" in data:\n",
    "                journal_info = data[\"message\"]\n",
    "                if \"ISSN\" in journal_info:\n",
    "                    new_df.loc[idx, \"issn\"] = journal_info[\"ISSN\"][0]\n",
    "                if \"title\" in journal_info:\n",
    "                    new_df.loc[idx, \"title\"] = journal_info[\"title\"]\n",
    "                    \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "# Iterate through the transaction list and search for corresponding ISSNs and titles from Google Books\n",
    "\n",
    "    elif len(x_short) == 13 or len(x_short) == 10:\n",
    "        try:\n",
    "            api_key = \"AIzaSyAvvo85uFwMwPVtpsPczXcQjX2Y1Iok0EI\"\n",
    "            url = \"https://www.googleapis.com/books/v1/volumes?q=isbn:\" + x_short + \"&key=\" + api_key\n",
    "            response = requests.get(url)\n",
    "            book_data = response.json()\n",
    "            \n",
    "            if 'items' in book_data:\n",
    "                items = book_data['items']\n",
    "                if len(items) > 0:\n",
    "                    volume_info = items[0]['volumeInfo']\n",
    "                    new_df.loc[idx, 'issn'] = volume_info['industryIdentifiers'][0]['identifier']\n",
    "                    new_df.loc[idx, 'title'] = volume_info['title']\n",
    "                    \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e86cf8-943d-4ece-9951-655cf8df5d5a",
   "metadata": {},
   "source": [
    "### 3. Update Data\n",
    "\n",
    "- This code first defines a function that merges the data and replaces the columns.\n",
    "- Then it saves the final results of our analysis to an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a028681b-45d9-45f7-96f7-bff162a4b809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your multipass ID:  muny\n",
      "Enter the file name for borrowing: Follow the naming convention `borrowing_YYYY_mm_dd.xlsx` or `lending_YYYY_mm_dd.xlsx`:  borrowing_2020_04_31.xlsx\n",
      "Enter the file name for lending: Follow the naming convention `borrowing_YYYY_mm_dd.xlsx` or `lending_YYYY_mm_dd.xlsx`:  lending_2020_04_31.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muny\\Anaconda3\\envs\\duq_ye\\lib\\site-packages\\pandas\\util\\_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "# Convert \"Transaction Number\" to numeric data type \n",
    "\n",
    "issn_title_lookup = pd.DataFrame(new_df, columns=['Transaction Number', 'issn', 'title'])\n",
    "issn_title_lookup['Transaction Number'] = pd.to_numeric(issn_title_lookup['Transaction Number'], downcast='integer')\n",
    "issn_title_lookup.columns = ['Transaction Number', 'issn', 'title']\n",
    "\n",
    "\"\"\" UPDATE DATA \"\"\"\n",
    "\n",
    "# Define a function to merge data and replace values\n",
    "def merge_data(df, lookup_df):\n",
    "    # Merge data\n",
    "    df_merged = pd.merge(df, lookup_df[['Transaction Number', 'issn', 'title']], how='left', on='Transaction Number')\n",
    "\n",
    "    # Replace the \"ISSN\" in df with the corresponding values from lookup_df where available\n",
    "    df_merged.loc[lookup_df['issn'].notnull(), 'ISSN'] = lookup_df.loc[lookup_df['issn'].notnull(), 'issn']\n",
    "\n",
    "    # Replace the \"Photo Journal Title\" column in df with the corresponding values from lookup_df where available\n",
    "    df_merged.loc[lookup_df['title'].notnull(), 'Photo Journal Title'] = lookup_df.loc[lookup_df['title'].notnull(), 'title']\n",
    "\n",
    "    # Convert \"Creation Date\" to datetime and extract \"year\"\n",
    "    df_merged['Creation Date'] = pd.to_datetime(df_merged['Creation Date']).dt.strftime('%Y-%m-%d')\n",
    "    df_merged['year'] = pd.DatetimeIndex(df_merged['Creation Date']).year\n",
    "\n",
    "    # Drop the 'issn' and 'TITLE' columns\n",
    "    df_merged.drop(['issn', 'title'], axis=1, inplace=True)\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "# Update data with issn_title_lookup data\n",
    "df_updated = merge_data(article, issn_title_lookup)\n",
    "\n",
    "# Filter for Borrowing and Lending requests\n",
    "borrowing = df_updated[df_updated[\"Process Type\"].isin([\"Borrowing\"])]\n",
    "lending = df_updated[df_updated[\"Process Type\"].isin([\"Lending\"])]\n",
    "\n",
    "\"\"\"SAVE\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "# Prompt user to input their multipass id\n",
    "multipass_id = input(\"Enter your multipass ID: \")\n",
    "\n",
    "# Define the file names and dataframes\n",
    "file_names = []\n",
    "borrowing.name = 'borrowing'\n",
    "lending.name = 'lending'\n",
    "data_frames = [borrowing, lending]\n",
    "\n",
    "# Loop through the data frames and ask for the file name\n",
    "for data_frame in data_frames:\n",
    "    save_name = input(f\"Enter the file name for {data_frame.name}: Follow the naming convention `borrowing_YYYY_mm_dd.xlsx` or `lending_YYYY_mm_dd.xlsx`: \")\n",
    "    file_names.append(save_name)\n",
    "\n",
    "# Loop through the file names and data frames\n",
    "for file_name, data_frame in zip(file_names, data_frames):\n",
    "    # Create the file path\n",
    "    file_path = f\"C:\\\\Users\\\\{multipass_id}\\\\Box\\\\Annual Report Procedures\\\\ILLiad Statistics\\\\ill_titles_powerbi\\\\{file_name}\"\n",
    "\n",
    "    # Write the data frame to the Excel file\n",
    "    data_frame.to_excel(file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
